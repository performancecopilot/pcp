# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
# or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
# for more details.
#
# Linux ZFS PMDA help file in the ASCII format
#
# lines beginning with a # are ignored
# lines beginning @ introduce a new entry of the form
#  @ metric_name oneline-text
#  help text goes
#  here over multiple lines
#  ...
#
# the metric_name is decoded against the default PMNS -- as a special case,
# a name of the form NNN.MM (for numeric NNN and MM) is interpreted as an
# instance domain identification, and the text describes the instance domain
#
# blank lines before the @ line are ignored

@ zfs.arc.hits
@ zfs.arc.misses
@ zfs.arc.demand_data_hits
@ zfs.arc.demand_data_misses
@ zfs.arc.demand_metadata_hits
@ zfs.arc.demand_metadata_misses
@ zfs.arc.prefetch_data_hits
@ zfs.arc.prefetch_data_misses
@ zfs.arc.prefetch_metadata_hits
@ zfs.arc.prefetch_metadata_misses
@ zfs.arc.mru_hits
@ zfs.arc.mru_ghost_hits
@ zfs.arc.mfu_hits
@ zfs.arc.mfu_ghost_hits
@ zfs.arc.deleted
@ zfs.arc.mutex_miss
Number of buffers that could not be evicted because the hash lock
was held by another thread.  The lock may not necessarily be held
by something using the same buffer, since hash locks are shared
by multiple buffers.
@ zfs.arc.access_skip
Number of buffers skipped when updating the access state due to the
header having already been released after acquiring the hash lock.
@ zfs.arc.evict_skip
Number of buffers skipped because they have I/O in progress, are
indirect prefetch buffers that have not lived long enough, or are
not from the spa we're trying to evict from.
@ zfs.arc.evict_not_enough
Number of times arc_evict_state() was unable to evict enough
buffers to reach its target amount.
@ zfs.arc.evict_l2_cached
@ zfs.arc.evict_l2_eligible
@ zfs.arc.evict_l2_ineligible
@ zfs.arc.evict_l2_skip
@ zfs.arc.hash_elements
@ zfs.arc.hash_elements_max
@ zfs.arc.hash_collisions
@ zfs.arc.hash_chains
@ zfs.arc.hash_chain_max
@ zfs.arc.p target size of MRU
@ zfs.arc.c target size of cache
@ zfs.arc.c_min min target cache size
@ zfs.arc.c_max max target cache size
@ zfs.arc.size
Not updated directly; only synced in arc_kstat_update
@ zfs.arc.compressed_size compressed size of entire ARC
Number of compressed bytes stored in the arc_buf_hdr_t's b_pabd.
Note that the compressed bytes may match the uncompressed bytes
if the block is either not compressed or compressed arc is disabled.
@ zfs.arc.uncompressed_size uncompressed size of entire ARC
Uncompressed size of the data stored in b_pabd. If compressed
arc is disabled then this value will be identical to the stat
above.
@ zfs.arc.overhead_size number of bytes in the arc from arc_buf_t's
Number of bytes stored in all the arc_buf_t's. This is classified
as "overhead" since this data is typically short-lived and will
be evicted from the arc when it becomes unreferenced unless the
zfs_keep_uncompressed_metadata or zfs_keep_uncompressed_level
values have been set (see comment in dbuf.c for more information).
@ zfs.arc.hdr_size
Number of bytes consumed by internal ARC structures necessary
for tracking purposes; these structures are not actually
backed by ARC buffers. This includes arc_buf_hdr_t structures
(allocated via arc_buf_hdr_t_full and arc_buf_hdr_t_l2only
caches), and arc_buf_t structures (allocated via arc_buf_t
cache).
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.data_size
Number of bytes consumed by ARC buffers of type equal to
ARC_BUFC_DATA. This is generally consumed by buffers backing
on disk user data (e.g. plain file contents).
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.metadata_size
Number of bytes consumed by ARC buffers of type equal to
ARC_BUFC_METADATA. This is generally consumed by buffers
backing on disk data that is used for internal ZFS
structures (e.g. ZAP, dnode, indirect blocks, etc).
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.dbuf_size
Number of bytes consumed by dmu_buf_impl_t objects.
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.dnode_size
Number of bytes consumed by dnode_t objects.
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.bonus_size bytes consumed by bonus buffers.
Number of bytes consumed by bonus buffers.
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.anon_size
Total number of bytes consumed by ARC buffers residing in the
arc_anon state. This includes *all* buffers in the arc_anon
state; e.g. data, metadata, evictable, and unevictable buffers
are all included in this value.
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.anon_evictable_data
Number of bytes consumed by ARC buffers that meet the
following criteria: backing buffers of type ARC_BUFC_DATA,
residing in the arc_anon state, and are eligible for eviction
(e.g. have no outstanding holds on the buffer).
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.anon_evictable_metadata
Number of bytes consumed by ARC buffers that meet the
following criteria: backing buffers of type ARC_BUFC_METADATA,
residing in the arc_anon state, and are eligible for eviction
(e.g. have no outstanding holds on the buffer).
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.mru_size
Total number of bytes consumed by ARC buffers residing in the
arc_mru state. This includes *all* buffers in the arc_mru
state; e.g. data, metadata, evictable, and unevictable buffers
are all included in this value.
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.mru_evictable_data
Number of bytes consumed by ARC buffers that meet the
following criteria: backing buffers of type ARC_BUFC_DATA,
residing in the arc_mru state, and are eligible for eviction
(e.g. have no outstanding holds on the buffer).
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.mru_evictable_metadata
Number of bytes consumed by ARC buffers that meet the
following criteria: backing buffers of type ARC_BUFC_METADATA,
residing in the arc_mru state, and are eligible for eviction
(e.g. have no outstanding holds on the buffer).
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.mru_ghost_size
Total number of bytes that *would have been* consumed by ARC
buffers in the arc_mru_ghost state. The key thing to note
here, is the fact that this size doesn't actually indicate
RAM consumption. The ghost lists only consist of headers and
don't actually have ARC buffers linked off of these headers.
Thus, *if* the headers had associated ARC buffers, these
buffers *would have* consumed this number of bytes.
@ zfs.arc.mru_ghost_evictable_data
Number of bytes that *would have been* consumed by ARC
buffers that are eligible for eviction, of type
ARC_BUFC_DATA, and linked off the arc_mru_ghost state.
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.mru_ghost_evictable_metadata
Number of bytes that *would have been* consumed by ARC
buffers that are eligible for eviction, of type
ARC_BUFC_METADATA, and linked off the arc_mru_ghost state.
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.mfu_size
Total number of bytes consumed by ARC buffers residing in the
arc_mfu state. This includes *all* buffers in the arc_mfu
state; e.g. data, metadata, evictable, and unevictable buffers
are all included in this value.
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.mfu_evictable_data
Number of bytes consumed by ARC buffers that are eligible for
eviction, of type ARC_BUFC_DATA, and reside in the arc_mfu
state.
Not updated directly; only synced in arc_kstat_update
@ zfs.arc.mfu_evictable_metadata
Number of bytes consumed by ARC buffers that are eligible for
eviction, of type ARC_BUFC_METADATA, and reside in the
arc_mfu state.
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.mfu_ghost_size
Total number of bytes that *would have been* consumed by ARC
buffers in the arc_mfu_ghost state. See the comment above
arcstat_mru_ghost_size for more details.
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.mfu_ghost_evictable_data
Number of bytes that *would have been* consumed by ARC
buffers that are eligible for eviction, of type
ARC_BUFC_DATA, and linked off the arc_mfu_ghost state.
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.mfu_ghost_evictable_metadata
Number of bytes that *would have been* consumed by ARC
buffers that are eligible for eviction, of type
ARC_BUFC_METADATA, and linked off the arc_mru_ghost state.
Not updated directly; only synced in arc_kstat_update.
@ zfs.arc.l2_hits
@ zfs.arc.l2_misses
@ zfs.arc.l2_feeds
@ zfs.arc.l2_rw_clash
@ zfs.arc.l2_read_bytes
@ zfs.arc.l2_write_bytes
@ zfs.arc.l2_writes_sent
@ zfs.arc.l2_writes_done
@ zfs.arc.l2_writes_error
@ zfs.arc.l2_writes_lock_retry
@ zfs.arc.l2_evict_lock_retry
@ zfs.arc.l2_evict_reading
@ zfs.arc.l2_evict_l1cached
@ zfs.arc.l2_free_on_write
@ zfs.arc.l2_abort_lowmem
@ zfs.arc.l2_cksum_bad
@ zfs.arc.l2_io_error
@ zfs.arc.l2_size
@ zfs.arc.l2_asize
@ zfs.arc.l2_hdr_size
@ zfs.arc.memory_throttle_count
@ zfs.arc.memory_direct_count
@ zfs.arc.memory_indirect_count
@ zfs.arc.memory_all_bytes
@ zfs.arc.memory_free_bytes
@ zfs.arc.memory_available_bytes
@ zfs.arc.arc_no_grow
@ zfs.arc.arc_tempreserve
@ zfs.arc.arc_loaned_bytes
@ zfs.arc.arc_prune
@ zfs.arc.arc_meta_used
@ zfs.arc.arc_meta_limit
ARC will evict meta buffers that exceed arc_meta_limit. This
tunable make arc_meta_limit adjustable for different workloads.
@ zfs.arc.arc_dnode_limit
@ zfs.arc.arc_meta_max max size of metadata
@ zfs.arc.arc_meta_min min size for metadata
@ zfs.arc.async_upgrade_sync
@ zfs.arc.demand_hit_predictive_prefetch
@ zfs.arc.demand_hit_prescient_prefetch
@ zfs.arc.arc_need_free bytes to be freed
@ zfs.arc.arc_sys_free target system free bytes
@ zfs.arc.arc_raw_size size of all b_rabd's in entire arc

@ zfs.abd.struct_size
Amount of memory occupied by all of the abd_t struct allocations 
@ zfs.abd.linear_cnt
The number of linear ABDs which are currently allocated, excluding
ABDs which don't own their data (for instance the ones which were
allocated through abd_get_offset() and abd_get_from_buf()). If an
ABD takes ownership of its buf then it will become tracked.
@ zfs.abd.linear_data_size
Amount of data stored in all linear ABDs tracked by linear_cnt 
@ zfs.abd.scatter_cnt
The number of scatter ABDs which are currently allocated, excluding
ABDs which don't own their data (for instance the ones which were
allocated through abd_get_offset()).
@ zfs.abd.scatter_data_size
Amount of data stored in all scatter ABDs tracked by scatter_cnt 
@ zfs.abd.scatter_chunk_waste
The amount of space wasted at the end of the last chunk across all
scatter ABDs tracked by scatter_cnt.
@ zfs.abd.scatter_order_0
The number of compound allocations of the 0th order.  These
allocations are spread over all currently allocated ABDs, and
act as a measure of memory fragmentation.
@ zfs.abd.scatter_order_1
The number of compound allocations of the 1st order.  These
allocations are spread over all currently allocated ABDs, and
act as a measure of memory fragmentation.
@ zfs.abd.scatter_order_2
The number of compound allocations of the 2nd order.  These
allocations are spread over all currently allocated ABDs, and
act as a measure of memory fragmentation.
@ zfs.abd.scatter_order_3
The number of compound allocations of the 3rd order.  These
allocations are spread over all currently allocated ABDs, and
act as a measure of memory fragmentation.
@ zfs.abd.scatter_order_4
The number of compound allocations of the 4th order.  These
allocations are spread over all currently allocated ABDs, and
act as a measure of memory fragmentation.
@ zfs.abd.scatter_order_5
The number of compound allocations of the 5th order.  These
allocations are spread over all currently allocated ABDs, and
act as a measure of memory fragmentation.
@ zfs.abd.scatter_order_6
The number of compound allocations of the 6th order.  These
allocations are spread over all currently allocated ABDs, and
act as a measure of memory fragmentation.
@ zfs.abd.scatter_order_7
The number of compound allocations of the 7th order.  These
allocations are spread over all currently allocated ABDs, and
act as a measure of memory fragmentation.
@ zfs.abd.scatter_order_8
The number of compound allocations of the 8th order.  These
allocations are spread over all currently allocated ABDs, and
act as a measure of memory fragmentation.
@ zfs.abd.scatter_order_9
The number of compound allocations of the 9th order.  These
allocations are spread over all currently allocated ABDs, and
act as a measure of memory fragmentation.
@ zfs.abd.scatter_order_10
The number of compound allocations of the 10th order.  These
allocations are spread over all currently allocated ABDs, and
act as a measure of memory fragmentation.
@ zfs.abd.scatter_page_multi_chunk
The number of scatter ABDs which contain multiple chunks.
ABDs are preferentially allocated from the minimum number of
contiguous multi-page chunks, a single chunk is optimal.
@ zfs.abd.scatter_page_multi_zone
The number of scatter ABDs which are split across memory zones.
ABDs are preferentially allocated using pages from a single zone.
@ zfs.abd.scatter_page_alloc_retry
The total number of retries encountered when attempting to
allocate the pages to populate the scatter ABD.
@ zfs.abd.scatter_sg_table_retry
The total number of retries encountered when attempting to
allocate the sg table for an ABD.

@ zfs.dbuf.cache_count statistics about the size of the dbuf cache
@ zfs.dbuf.cache_size_bytes statistics about the size of the dbuf cache
@ zfs.dbuf.cache_size_bytes_max statistics about the size of the dbuf cache
@ zfs.dbuf.cache_target_bytes statistics regarding the bounds on the dbuf cache size
@ zfs.dbuf.cache_lowater_bytes statistics regarding the bounds on the dbuf cache size
@ zfs.dbuf.cache_hiwater_bytes statistics regarding the bounds on the dbuf cache size
@ zfs.dbuf.cache_total_evicts total number of dbuf cache evictions that have occurred
@ zfs.dbuf.cache_level_0 the distribution of dbufs level 0 in the cache
@ zfs.dbuf.cache_level_1 the distribution of dbufs level 1 in the cache
@ zfs.dbuf.cache_level_2 the distribution of dbufs level 2 in the cache
@ zfs.dbuf.cache_level_3 the distribution of dbufs level 3 in the cache
@ zfs.dbuf.cache_level_4 the distribution of dbufs level 4 in the cache
@ zfs.dbuf.cache_level_5 the distribution of dbufs level 5 in the cache
@ zfs.dbuf.cache_level_6 the distribution of dbufs level 6 in the cache
@ zfs.dbuf.cache_level_7 the distribution of dbufs level 7 in the cache
@ zfs.dbuf.cache_level_8 the distribution of dbufs level 8 in the cache
@ zfs.dbuf.cache_level_9 the distribution of dbufs level 9 in the cache
@ zfs.dbuf.cache_level_10 the distribution of dbufs level 10 in the cache
@ zfs.dbuf.cache_level_11 the distribution of dbufs level 11 in the cache
@ zfs.dbuf.cache_level_0_bytes the total size of dbufs level 0 in the cache
@ zfs.dbuf.cache_level_1_bytes the total size of dbufs level 1 in the cache
@ zfs.dbuf.cache_level_2_bytes the total size of dbufs level 2 in the cache
@ zfs.dbuf.cache_level_3_bytes the total size of dbufs level 3 in the cache
@ zfs.dbuf.cache_level_4_bytes the total size of dbufs level 4 in the cache
@ zfs.dbuf.cache_level_5_bytes the total size of dbufs level 5 in the cache
@ zfs.dbuf.cache_level_6_bytes the total size of dbufs level 6 in the cache
@ zfs.dbuf.cache_level_7_bytes the total size of dbufs level 7 in the cache
@ zfs.dbuf.cache_level_8_bytes the total size of dbufs level 8 in the cache
@ zfs.dbuf.cache_level_9_bytes the total size of dbufs level 9 in the cache
@ zfs.dbuf.cache_level_10_bytes the total size of dbufs level 10 in the cache
@ zfs.dbuf.cache_level_11_bytes the total size of dbufs level 11 in the cache
@ zfs.dbuf.hash_hits statistics about the dbuf hash table
@ zfs.dbuf.hash_misses statistics about the dbuf hash table 
@ zfs.dbuf.hash_collisions statistics about the dbuf hash table
@ zfs.dbuf.hash_elements statistics about the dbuf hash table
@ zfs.dbuf.hash_elements_max statistics about the dbuf hash table
@ zfs.dbuf.hash_chains
Number of sublists containing more than one dbuf in the dbuf
hash table. Keep track of the longest hash chain.
@ zfs.dbuf.hash_chain_max
@ zfs.dbuf.hash_insert_race
Number of times a dbuf_create() discovers that a dbuf was
already created and in the dbuf hash table.
@ zfs.dbuf.metadata_cache_count statistics about the size of the metadata dbuf cache
@ zfs.dbuf.metadata_cache_size_bytes statistics about the size of the metadata dbuf cache
@ zfs.dbuf.metadata_cache_size_bytes_max statistics about the size of the metadata dbuf cache
@ zfs.dbuf.metadata_cache_overflow
For diagnostic purposes, this is incremented whenever we can't add
something to the metadata cache because it's full, and instead put
the data in the regular dbuf cache.

@ zfs.dmu_tx.assigned
@ zfs.dmu_tx.delay
@ zfs.dmu_tx.error
@ zfs.dmu_tx.suspended
@ zfs.dmu_tx.group
@ zfs.dmu_tx.memory_reserve
@ zfs.dmu_tx.memory_reclaim
@ zfs.dmu_tx.dirty_throttle
@ zfs.dmu_tx.dirty_delay
@ zfs.dmu_tx.dirty_over_max
@ zfs.dmu_tx.dirty_frees_delay
@ zfs.dmu_tx.quota

@ zfs.dnode.hold_dbuf_hold
Number of failed attempts to hold a meta dnode dbuf.
@ zfs.dnode.hold_dbuf_read
Number of failed attempts to read a meta dnode dbuf.
@ zfs.dnode.hold_alloc_hits
Number of times dnode_hold(..., DNODE_MUST_BE_ALLOCATED) was able
to hold the requested object number which was allocated.  This is
the common case when looking up any allocated object number.
@ zfs.dnode.hold_alloc_misses
Number of times dnode_hold(..., DNODE_MUST_BE_ALLOCATED) was not
able to hold the request object number because it was not allocated.
@ zfs.dnode.hold_alloc_interior
Number of times dnode_hold(..., DNODE_MUST_BE_ALLOCATED) was not
able to hold the request object number because the object number
refers to an interior large dnode slot.
@ zfs.dnode.hold_alloc_lock_retry
Number of times dnode_hold(..., DNODE_MUST_BE_ALLOCATED) needed
to retry acquiring slot zrl locks due to contention.
@ zfs.dnode.hold_alloc_lock_misses
Number of times dnode_hold(..., DNODE_MUST_BE_ALLOCATED) did not
need to create the dnode because another thread did so after
dropping the read lock but before acquiring the write lock.
@ zfs.dnode.hold_alloc_type_none
Number of times dnode_hold(..., DNODE_MUST_BE_ALLOCATED) found
a free dnode instantiated by dnode_create() but not yet allocated
by dnode_allocate().
@ zfs.dnode.hold_free_hits
Number of times dnode_hold(..., DNODE_MUST_BE_FREE) was able
to hold the requested range of free dnode slots.
@ zfs.dnode.hold_free_misses
Number of times dnode_hold(..., DNODE_MUST_BE_FREE) was not
able to hold the requested range of free dnode slots because
at least one slot was allocated.
@ zfs.dnode.hold_free_lock_misses
Number of times dnode_hold(..., DNODE_MUST_BE_FREE) was not
able to hold the requested range of free dnode slots because
after acquiring the zrl lock at least one slot was allocated.
@ zfs.dnode.hold_free_lock_retry
Number of times dnode_hold(..., DNODE_MUST_BE_FREE) needed
to retry acquiring slot zrl locks due to contention.
@ zfs.dnode.hold_free_refcount
Number of times dnode_hold(..., DNODE_MUST_BE_FREE) requested
a range of dnode slots which were held by another thread.
@ zfs.dnode.hold_free_overflow
Number of times dnode_hold(..., DNODE_MUST_BE_FREE) requested
a range of dnode slots which would overflow the dnode_phys_t.
@ zfs.dnode.free_interior_lock_retry
Number of times dnode_free_interior_slots() needed to retry
acquiring a slot zrl lock due to contention.
@ zfs.dnode.allocate
Number of new dnodes allocated by dnode_allocate().
@ zfs.dnode.reallocate
Number of dnodes re-allocated by dnode_reallocate().
@ zfs.dnode.buf_evict
Number of meta dnode dbufs evicted.
@ zfs.dnode.alloc_next_chunk
Number of times dmu_object_alloc*() reached the end of the existing
object ID chunk and advanced to a new one.
@ zfs.dnode.alloc_race
Number of times multiple threads attempted to allocate a dnode
from the same block of free dnodes.
@ zfs.dnode.alloc_next_block
Number of times dmu_object_alloc*() was forced to advance to the
next meta dnode dbuf due to an error from  dmu_object_next().
@ zfs.dnode.move_invalid
Statistics for tracking dnodes which have been moved.
@ zfs.dnode.move_recheck1
Statistics for tracking dnodes which have been moved.
@ zfs.dnode.move_recheck2
Statistics for tracking dnodes which have been moved.
@ zfs.dnode.move_special
Statistics for tracking dnodes which have been moved.
@ zfs.dnode.move_handle
Statistics for tracking dnodes which have been moved.
@ zfs.dnode.move_rwlock
Statistics for tracking dnodes which have been moved.
@ zfs.dnode.move_active
Statistics for tracking dnodes which have been moved.

@ zfs.fm.erpt_dropped number of erpts dropped on post
@ zfs.fm.erpt_set_failed number of erpt set failures
@ zfs.fm.fmri_set_failed number of fmri set failures
@ zfs.fm.payload_set_failed number of payload set failures

@ zfs.vdev.cache.delegations
@ zfs.vdev.cache.hits
@ zfs.vdev.cache.misses
@ zfs.vdev.mirror.rotating_linear
New IO follows directly the last IO 
@ zfs.vdev.mirror.rotating_offset
New IO is within zfs_vdev_mirror_rotating_seek_offset of the last 
@ zfs.vdev.mirror.rotating_seek
New IO requires random seek 
@ zfs.vdev.mirror.non_rotating_linear
New IO follows directly the last IO  (nonrot) 
@ zfs.vdev.mirror.non_rotating_seek
New IO requires random seek (nonrot) 
@ zfs.vdev.mirror.preferred_found
Preferred child vdev found 
@ zfs.vdev.mirror.preferred_not_found
Preferred child vdev not found or equal load  

@ zfs.xuio.onloan_rbuf loaned yet not returned arc_buf read
@ zfs.xuio.onloan_wbuf loaned yet not returned arc_buf written
@ zfs.xuio.rbuf_copied whether a copy is made when loaning out a read buffer 
@ zfs.xuio.rbuf_nocopy whether a copy is made when loaning out a read buffer 
@ zfs.xuio.wbuf_copied whether a copy is made when assigning a write buffer 
@ zfs.xuio.wbuf_nocopy whether a copy is made when assigning a write buffer 

@ zfs.zfetch.hits
@ zfs.zfetch.misses
@ zfs.zfetch.max_streams maximum number of streams per zfetch

@ zfs.zil.commit_count
Number of times a ZIL commit (e.g. fsync) has been requested.
@ zfs.zil.commit_writer_count
Number of times the ZIL has been flushed to stable storage.
This is less than zil_commit_count when commits are merged
(see the documentation above zil_commit()).
@ zfs.zil.itx_count
Number of transactions (reads, writes, renames, etc.)
that have been committed.
@ zfs.zil.itx_indirect_count
The number of indirect transactions.
@ zfs.zil.itx_indirect_bytes
The size of the the large data portions to write.
Note that bytes accumulates the length of the transactions
(i.e. data), not the actual log record sizes.
@ zfs.zil.itx_copied_count
The number of transactions copied into lr_write_t.
@ zfs.zil.itx_copied_bytes
The size of the data copied into lr_write_t.
Note that bytes accumulates the length of the transactions
(i.e. data), not the actual log record sizes.
@ zfs.zil.itx_needcopy_count
The number of transactions that need to be copied if pushed.
@ zfs.zil.itx_needcopy_bytes
The size of the data that needs to be copied if pushed.
Note that bytes accumulates the length of the transactions
(i.e. data), not the actual log record sizes.
@ zfs.zil.itx_metaslab_normal_count
The number of transactions which have been allocated to the normal
(i.e. not slog) storage pool. Note that bytes accumulate
the actual log record sizes - which do not include the actual
data in case of indirect writes.
@ zfs.zil.itx_metaslab_normal_bytes
The size of transactions which have been allocated to the normal
(i.e. not slog) storage pool. Note that bytes accumulate
the actual log record sizes - which do not include the actual
data in case of indirect writes.
@ zfs.zil.itx_metaslab_slog_count
The number of transactions which have been allocated to the slog storage pool.
If there are no separate log devices, this is the same as the
normal pool.
@ zfs.zil.itx_metaslab_slog_bytes
The size of transactions which have been allocated to the slog storage pool.
If there are no separate log devices, this is the same as the
normal pool.

@ zfs.pool.state number corresponding to the pool state
OFFLINE  = 0, ONLINE  = 1, 
DEGRADED = 2, FAULTED = 3, REMOVED = 4, 
UNAVAIL  = 5, UNKNOWN = 13
@ zfs.pool.nread number of bytes read
@ zfs.pool.nwritten number of bytes written
@ zfs.pool.reads number of read operations
@ zfs.pool.writes number of write operations
@ zfs.pool.wtime cumulative wait (pre-service) time
@ zfs.pool.wlentime cumulative wait len*time product
@ zfs.pool.wlastupdate last time wait queue changed
@ zfs.pool.rtime cumulative run (service) time
@ zfs.pool.rlentime cumulative run length*time product
@ zfs.pool.rlastupdate last time run queue changed
@ zfs.pool.wcnt count of elements in wait state
@ zfs.pool.rcnt count of elements in run state
