#!/usr/bin/env pmpython
'''
Performance Metrics Domain Agent exporting Prometheus endpoint metrics.
'''
#
# Copyright (c) 2017 Ronak Jain.
# Copyright (c) 2017 Red Hat, Inc.
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
# or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
# for more details.
#

import cpmapi as c_api
import cpmda
from pcp.pmapi import pmUnits, pmContext, pmErr
from pcp.pmda import PMDA, pmdaMetric, pmdaIndom, pmdaInstid

import argparse
from collections import OrderedDict
from ctypes import c_int
import copy
import errno
import math
import json
import os
import re
import sys
import time
import pickle
import requests
import threading


MAX_CLUSTER = 0xfff    # ~ max. number of prometheus sources
MAX_METRIC = 0x3ff     # ~ max. number of metrics per source
MAX_INDOM = 0x7fffffff # coincidentally, ~ product of above

# These numbers are combined to create uniqe numbers for several
# purposes.  The first two types are used only for internal
# pmdaprometheus purposes, and are not visible as indoms to pmapi
# clients.
#
# indom# 0: maps source nicknames to 12-bit "cluster" numbers, cluster#0 is not used
# indom# 1..4095: for each source=cluster, map metric names to pmid numbers
# indom# 4096 + cluster#*1024 ...+1023:  actual pmns indom for each metric


class Metric(object):
        ''' Metric information class '''
        def __init__(self,source,name,metricnum,instances,pcpline,helpline,typeline):
                self.source = source
                self.name = name
                self.metricnum = metricnum # seen during fetch callbacks
                self.pmid = source.pmda.pmid(source.cluster,metricnum) # add domain/cluster#
                self.indom_number = (MAX_CLUSTER+1 +
                                     (source.cluster * (MAX_METRIC+1)) +
                                     metricnum)
                self.pcpline = pcpline
                self.typeline = typeline
                self.values = {} # instance-vector-to-value
                self.assign_metadata()
                if instances:
                        self.mindom = self.source.pmda.indom(self.indom_number) # add domain#
                        self.indom_table = PersistentNameTable(self.source.pmda,
                                                               self.indom_number, MAX_INDOM)
                else:
                        self.mindom = c_api.PM_INDOM_NULL
                        self.indom_table = None
                self.obj = pmdaMetric(self.pmid,self.mtype,self.mindom,self.msem,self.munits)
                if helpline: # it could be None!
                        self.description = helpline # XXX unescape
                else:
                        self.description = ''

                try:
                        self.source.pmda.add_metric(self.mname, self.obj, self.description)
                        self.source.pmda.set_need_refresh()
                except Exception as e:
                        self.source.pmda.log("Cannot add metric %s (%d): %s" % (self.mname, self.pmid, e))
                self.source.pmda.debug("created metric %#x (%s)" % (self.pmid, self.mname))


        def assign_metadata(self):
                ''' Compute metric metadata self.{mtype,mname,msem,munits}
                from the available information already stored in self.
                '''
                self.mtype = c_api.PM_TYPE_DOUBLE # NB: allow overriding sometime

                # Split the prometheus metric name by "_", to help
                # decode convention for squishing unit/scale data.
                pieces = self.name.split('_')
                
                # XXX: pcpline semantics
                if (self.typeline == 'counter'
                    or 'total' in pieces or 'count' in pieces or 'sum' in pieces):
                        self.msem = c_api.PM_SEM_COUNTER
                else:
                        self.msem = c_api.PM_SEM_INSTANT

                if self.pcpline:
                        self.mname = 'prometheus.' + self.source.name + '.' + self.pcpline # XXX: split once it carries sem/units
                else:
                        self.mname = 'prometheus.' + self.source.name + '.' + self.name.replace(":",".")
                        
                # XXX: pcpline units
                if ('seconds' in pieces):
                        self.munits = pmUnits(0,1,0,0,3,0)
                elif ('microseconds' in pieces): # not listed in https://prometheus.io/docs/practices/naming/
                        self.munits = pmUnits(0,1,0,0,1,0)
                elif ('bytes' in pieces):
                        self.munits = pmUnits(1,0,0,1,0,0)
                else:
                        self.munits = pmUnits(0,0,0,0,0,0) # default, dimensionless old-school count

                assert self.munits and self.msem and self.mname and self.mtype

                
        def clear_values(self):
                ''' Erase all stored instance/value pairs, in anticipation of a new set. '''
                self.values.clear()
        
        def store_inst(self,labels,value):
                ''' Store given new instance/value pair. '''
                
                assert (labels is None) == (self.indom_table is None) # no metric indom flipflop
                if labels is None:
                        self.values[c_api.PM_IN_NULL] = float(value)
                else:
                        if self.pcpline: # pmwebd
                                instname = labels['instance']
                        else:
                                instname = str(labels)
                        # self.source.pmda.debug("store %s instance %s value %s" % (self.pcpline, instname, value))
                        inst = self.indom_table.intern_lookup_value(instname)
                        self.values[inst] = float(value)
                        self.indom_table.save() # XXX: ideally less frequently
                        
        def fetch_inst(self,inst): # fetch instance
                if inst in self.values:
                        return [self.values[inst], 1]
                else:
                        # NB: same error if we lack a value for this metric altogether,
                        # or if a wrong/obsolete instance# is being sought.
                        return [c_api.PM_ERR_INST, 0]

                
class PersistentNameTable(object):
        '''Persistent name table.  Answers name-to-number queries by assigning
        persistent ids.  Updates pmda's indom table intermittently.
        Persistent by saving dictionary in $PCP_VAR_DIR/pmdas/,
        similarly to how pmdaCache functions do.
        '''
 
        def __init__(self,pmda,indom,maxnum):
                self.pmda = pmda
                self.indom = indom
                self.maxnum = maxnum
                self.need_save = False
                self.store_file_name = '%s/config/pmda/%d.%d.py' % (os.environ['PCP_VAR_DIR'],
                                                                    pmda.domain, indom)
                try: # slightly used!
                        with open(self.store_file_name,'rb') as f:
                                self.instances = pickle.load(f,encoding="bytes")
                                self.pmda.debug("loaded %s" % self.store_file_name)
                                self.need_save = True # to push values down into c pmda layer
                except Exception as e: # new!
                        self.instances = [] # won't be saved till nonempty

                self.names_to_instances = {}
                for i,n in enumerate(self.instances):
                        self.names_to_instances[n] = i
                # prime the pmda indom table with an empty list; the pmdaIndom
                # object will be replaced shortly within .replace_indom()
                self.pmdaindom = pmdaIndom(pmda.indom(self.indom), [])
                self.pmda.add_indom(self.pmdaindom)
                self.save() # replace it with real data now, if non-empty
                
        def save(self):
                '''Push values to the PMDA layer as well as to the backing store file.'''
                if self.need_save:
                        # save to the pmda C layer
                        indom_array = [] # pmdaInstid array, computed on demand
                        for i,n in enumerate(self.instances):
                                indom_array.append(pmdaInstid(c_int(i),str(n)))
                        # NB: use replace_indom(int,[...]) overload, to pass indom_array,
                        # else it gets ignored
                        self.pmda.replace_indom(self.pmda.indom(self.indom), indom_array)
                        self.pmda.set_need_refresh()
                        # save to disk too
                        try: # slightly used!
                                with open(self.store_file_name,'wb') as f:
                                        pickle.dump(self.instances, f, protocol=0) # 0: most compatible
                                        self.pmda.debug("saved %s, %d instances" % (self.store_file_name, len(self.instances)))
                                self.need_save = False # reset only on success
                        except Exception as e:
                                self.pmda.log("cannot save %s: %s" % (self.store_file_name, e))
                        

        def intern_lookup_value(self, name):
                '''Add/lookup given name, return its persistent identifier.'''
                if name in self.names_to_instances: # fast path
                        return self.names_to_instances[name]
                else: # new name
                        num = len(self.instances)
                        if (num > self.maxnum):
                                raise ValueError('Too many (%d) different names' % num)
                        self.instances.append(name)
                        self.names_to_instances[name] = num
                        assert self.instances[num] == name
                        self.need_save = True
                        return num

        
class SampleLineParser(object):
        '''A parser for one metric [{instance}] value [timestamp] line.  A
        state machine required since we're lexing text with embedded
        quoted freeform strings with punctuation, etc., so can't
        simply do substring searching.
        '''

        def parse_metric_name_start(self,char):
                if char.isspace():
                        pass
                else:
                        self.state = self.parse_metric_name
                        self.name = char

        def parse_metric_name(self,char):
                if char == '{':
                        self.state = self.parse_label_name_start
                        self.labels = {}
                elif char.isspace():
                        self.state = self.parse_post_metric_name
                else:
                        self.name += char

        def parse_post_metric_name(self,char):
                if char.isspace():
                        pass
                elif char == '{':
                        self.state = self.parse_label_name_start
                        self.labels = {}
                else:
                        self.state = self.parse_value
                        self.value = char

        def parse_label_name_start(self,char):
                if char.isspace():
                        pass
                elif char == '}':
                        self.state = self.parse_post_labels
                else:
                        self.state = self.parse_label_name
                        self.lname = char

        def parse_label_name(self,char):
                if char.isspace():
                        self.state = self.parse_label_equals
                elif char == '=':
                        self.state = self.parse_label_value_start
                else:
                        self.lname += char

        def parse_label_equals(self,char):
                if char.isspace():
                        pass
                elif char == '=':
                        self.state = self.parse_label_value_start
                else:
                        raise ValueError("Expected =")

        def parse_label_value_start(self,char):
                if char.isspace():
                        pass
                elif char == '"':
                        self.state = self.parse_label_value
                        self.lvalue = ""
                else:
                        raise ValueError("Expected \"")

        def parse_label_value(self,char):
                if char == '\\':
                        self.state = self.parse_label_value_escapechar
                elif char == '"':
                        self.state = self.post_label_value
                        self.labels[self.lname]=self.lvalue
                        self.lname = None
                        self.lvalue = None
                else:
                        self.lvalue += char
                                              
        def parse_label_value_escapechar(self,char):
                # XXX: maybe pass through \-escaped identifiers literally through to pcp
                # otherwise we'd have to filter them out at indom-instance-name creation
                if char == '\\':
                        self.state = self.parse_label_value
                        self.lvalue += '\\'
                elif char == 'n':
                        self.state = self.parse_label_value
                        self.lvalue += '\n'
                elif char == '"':
                        self.state = self.parse_label_value
                        self.lvalue += '\"'
                else:
                        self.state = self.parse_label_value
                        self.lvalue += '\\' + char # transcribe \XYZ literally
        
        def post_label_value(self,char):
                if char.isspace():
                        pass
                elif char == ',':
                        self.state = self.parse_label_name_start
                elif char == '}':
                        self.state = self.parse_post_labels
                else:
                        raise ValueError("Expected , or }")

        def parse_post_labels(self,char):
                if char.isspace():
                        pass
                else:
                        self.state = self.parse_value
                        self.value = char
                                              
        def parse_value(self,char):
                if char.isspace(): # timestamp possibly following
                        self.state = self.parse_chomp
                else:
                        self.value += char

        def parse_chomp(self,char): # ignored stuff
                pass

        def __init__(self,line):
                # mis-initialize output variables to force state
                # machine transitions to do it right
                self.name = None
                self.value = None
                self.labels = None
                self.lname = None
                self.lvalue = None

                # run state machine
                self.state = self.parse_metric_name_start
                for char in line:
                        self.state(char)

                assert self.name
                assert self.value

                                              
class Source(object):
        '''An instance of this class represents a distinct Prometheus exporter,
        identified by a nickname (the next PMNS component beneath prometheus.*),
        and a URL.  Metrics will show up at prometheus.NICKNAME.MET.RIC as/when
        the source is online.
        '''

        def __init__(self, name, cluster, path, pmda):
                self.name = name # source nickname
                self.cluster = cluster # unique/persistent id# for nickname
                self.path = path # pathname to .url file
                self.pmda = pmda # the shared pmda

                self.requests = requests.Session() # allow persistent connections etc.
                
                # persistently assign numeric id to our metrics
                self.pmids_table = PersistentNameTable(self.pmda, cluster, MAX_METRIC)
                
                self.metrics_by_name = {} # name -> Metric
                self.metrics_by_num = {} # number (last component of pmid) -> Metric
                

        def old_enough_for_refresh(self):
                '''But what's "old"?  Aye, there's the rub.  If it's empty (no
                metrics), then it has probably never been connected to
                successfully.  

                OTOH, if it hasn't been fetched from "recently", maybe
                it grew new metrics, and may need a look-see.  So we
                could track the last time a fetch was done to this source,
                and "time out" the PMNS from it.  XXX
                '''
                return len(self.metrics_by_name) == 0
                
        def parse_metric_line(self,line,pcpline,helpline,typeline):
                '''
                Parse the sample line, identify/create corresponding metric & instance.
                '''
                try:
                        sp = SampleLineParser(line)
                        # self.pmda.debug("parsed '%s' -> %s %s %s" % (line, sp.name, sp.labels, sp.value))
                        if sp.name in self.metrics_by_name:
                                m = self.metrics_by_name[sp.name]
                                assert self.metrics_by_num[m.metricnum] == m
                        else:
                                metricnum = self.pmids_table.intern_lookup_value(sp.name)
                                m = Metric(self,sp.name,metricnum,sp.labels,
                                           pcpline,helpline,typeline)
                                self.metrics_by_name[sp.name] = m
                                self.metrics_by_num[metricnum] = m  # not pmid!

                        m.store_inst(sp.labels,sp.value)
                except Exception as e:
                        self.pmda.log("cannot parse/store %s: %s" % (line, e))
                pass


        def parse_lines(self,text):
                '''Refresh all the metric metadata as it is found, including creating
                new metrics.  Store away metric values for subsequent
                fetch()es.  Parse errors may result in exceptions.
                That's OK, we don't try heroics to parse non-compliant
                data.  Return number of metrics extracted.
                '''

                num_metrics = 0
                lines = text.splitlines()
                pcpline = None
                helpline = None
                typeline = None
                state="metadata"
                for line in lines:
                        # self.pmda.debug("line: %s state: %s" % (line, state))
                        l = line.strip() # whitespace
                        if l == "": # blank line, ignore, no state change
                                continue
                        elif l.startswith("#"): # comment
                                if state == "metrics":
                                        state = "metadata"
                                        pcpline = None # NB: throw away previous block's metadata
                                        helpline = None
                                        typeline = None

                                lp = l.split()
                                if len(lp) < 2:
                                        continue
                                # NB: for a well-formed exporter file,
                                # the # metadata blocks must precede
                                # the metric values; we can ignore
                                # lp[2].
                                if lp[1] == 'PCP': # XXX: extend, regularize, document
                                        pcpline = ' '.join(lp[2:])
                                elif lp[1] == 'HELP':
                                        # assume lp[2] matches metric name
                                        helpline = ' '.join(lp[3:]) # XXX unescape \\ \n
                                elif lp[1] == 'TYPE':
                                        # assume lp[2] matches metric name
                                        typeline = ' '.join(lp[3:])
                                else:
                                        pass # ignore other comment lines
                        else: # metric{...} value line
                                state = "metrics"
                                # NB: could verify helpline/typeline lp[2] matches,
                                # but we don't have to go out of our way to support
                                # non-compliant exporters.
                                self.parse_metric_line(l,pcpline,helpline,typeline)
                                num_metrics += 1

                # NB: this logic only ever -adds- Metrics to a Source.  If a source
                # stops supplying some metrics, then a PCP app will see a PM_ERR_INST
                # coming back when it tries to fetch them.  We could perhaps keep the
                # set of -current- metrics fresh, i.e., track any metrics that were
                # in the Source but were not processed by any parse_metric_line() call.
                # Then we could remove the Metric, and thereby trigger a PM_ERR_PMID
                # for them.  In both cases though, we have no values.
                
                return num_metrics
                

        def refresh(self):
                '''
                Find the target URL by reading .url file.
                Fetch the target URL.
                Parse the resulting document.
                '''
                # clear cached values from all my metrics
                for n,m in self.metrics_by_name.items():
                        m.clear_values()
                # XXX: ditch metrics no longer found in document

                # (re)read the URL from given file
                try:
                        url = open(self.path,'r').read().strip()
                except Exception as e:
                        self.pmda.log("cannot read %s: %s" % (self.path, e))
                        return
                # fetch the URL
                try:
                        if url.startswith('file://'):
                                t = open(url[7:],'r').read()
                        else:
                                r = self.requests.get(url,timeout=1) # XXX parametrize
                                r.raise_for_status() # non-200?  ERROR
                                t = r.text
                        s = self.parse_lines(t)
                        self.pmids_table.save()
                        self.pmda.debug("fetched %d bytes with %d metrics from %s" % (len(t), s, url))
                except Exception as e:
                        self.pmda.log("cannot fetch %s: %s" % (url, e))
                        return
                
        def fetch(self, item, inst):
                ''' Retrieve metric/instance values that ought to have been found
                by a recent refresh().  PM_ERR_AGAIN signals a no go.'''
                try:
                        m = self.metrics_by_num[item]
                        return m.fetch_inst(inst)
                except Exception as e:
                        self.pmda.log("cannot fetch item %d inst %d: %s" % (item,inst,e))
                        return [c_api.PM_ERR_AGAIN, 0]


class PrometheusPMDA(PMDA):
        def __init__(self,pmda_name,domain,config):
                ''' Initialize the PMDA
                '''
                # urgent: say hi the invoking pmcd, redirect stderr etc.
                PMDA.__init__(self,pmda_name,domain)
                self.connect_pmcd()
                # now everything else may take time
                self.pmda_name = pmda_name
                self.config_dir = config
                self.config_dir_ctime = None
                self.debug_flag = ('PCP_PYTHON_DEBUG' in os.environ)

                # the list of configured sources
                self.source_by_name = {}
                # persistently assign numeric id to source names -> pmid "cluster" numbers
                self.cluster_table = PersistentNameTable(self, 0, MAX_CLUSTER)
                reserved_cluster = self.cluster_table.intern_lookup_value("*reserved-source2cluster*")
                assert reserved_cluster == 0
                self.source_by_cluster = {}

                # Add a IS_DYNAMIC_ROOT metric that serves as a reminder to
                # pmcd to delegate all pmns requests to us.  Do it early, before
                # other metrics may populate beneath the prometheus.* prefix.
                dynamic_pmid = (0 << 31) | (511 << 22) | (144 << 10) | 0
                dynamic_root = pmdaMetric(dynamic_pmid,0,0,0,pmUnits())
                self.add_metric('prometheus',dynamic_root,'dynamic root for prometheus metrics')
                self.set_need_refresh()

                # used all the time, but we welcome it only for initial pmns population purposes
                self.set_refresh_metrics(self.refresh_metrics_for_pmns)
                # used during fetch
                self.set_refresh_all(self.refresh_some_clusters_for_fetch) # "all" is a misnomer
                self.set_fetch_callback(self.fetch_callback)


        def assert_source_invariants(self, name=None, cluster=None):
                '''
                Assert some invariants about the known sources
                '''
                if name:
                        s = self.source_by_name[name]
                        assert s == self.source_by_cluster[s.cluster]
                if cluster:
                        s = self.source_by_cluster[cluster]
                        assert s == self.source_by_name[s.name]

                       
        def rescan_confdir(self):
                '''Scan the configuration directory for any new .url files containing
                prometheus URLs.  Ensure there is a Source registered in
                the self.source_by_name dictionary for each one.

                If the config_dir hasn't changed lately, do nothing.
                This is important because this callback is invoked
                -all-the-time- by src/python/pmda.c.
                '''
                try:
                        ctime = os.path.getctime(self.config_dir)
                        if not self.config_dir_ctime or self.config_dir_ctime < ctime:
                                self.config_dir_ctime = ctime
                                # fall through
                        else: # no change, don't rescan directory
                                return
                except:
                        # If the stat failed, there's not much we can do.
                        # pass # could fall through
                        return
                
                nickname_regexp = re.compile(r"^[A-Za-z]\w*$")
                
                # XXX: nuke sources related to removed files
                self.log("walking %s, ctime %s" % (self.config_dir, self.config_dir_ctime))
                save_cluster_table = False
                for root, dirs, files in os.walk(self.config_dir):
                        for file in files:
                                # compute nickname for source:
                                # the part of the filename before .url
                                file_split = os.path.splitext(file)
                                self.debug("found %s/%s => %s" % (root, file, file_split))
                                if len(file_split) != 2 or file_split[1] != ".url":
                                        continue
                                name = file_split[0]
                                if not nickname_regexp.match(name):
                                        self.log("Bad nickname %s" % file)
                                        continue

                                if name in self.source_by_name:
                                        self.assert_source_invariants(name=name)
                                        pass
                                else:
                                        try:
                                                path = os.path.join(root, file)
                                                cluster = self.cluster_table.intern_lookup_value(name)
                                                source = Source(name, cluster, path, self)
                                                self.source_by_name[source.name] = source
                                                self.source_by_cluster[source.cluster] = source
                                                save_cluster_table = True
                                                self.log("Found source %s cluster %d" % (name, cluster))
                                        except Exception as e:
                                                self.log("Error allocating new cluster/source %s (%s)" % (name, e))
                if save_cluster_table:
                        self.cluster_table.save()


        def refresh_metrics_for_pmns(self):
                '''Refresh our list of Sources.  Then have each "old" Source do a
                fetch, so as to populate/refresh the PMNS.
                '''
                self.rescan_confdir() # get our Source list up to date
                
                # do a batch fetch of all empty sources to ensure pmns is populated
                clusters=[]
                for k,v in self.source_by_cluster.items():
                        if v.old_enough_for_refresh():
                                clusters.append(k)
                self.refresh_some_clusters_for_fetch(clusters)

                
        def fetch_callback(self, cluster, item, inst):
                ''' Main fetch callback which returns the value of the metric '''
                self.assert_source_invariants(cluster=cluster)
                try:
                        if cluster in self.source_by_cluster:
                                return self.source_by_cluster[cluster].fetch(item, inst)
                        else:
                                return [c_api.PM_ERR_PMID, 0]
                except Exception as e:
                        return [c_api.PM_ERR_AGAIN, 0] # was there before

        def refresh_worker(self,cluster):
                try:
                        self.assert_source_invariants(cluster=cluster)
                        self.source_by_cluster[cluster].refresh()
                except Exception as e:
                        self.log("Cannot refresh cluster %d: %s" % (cluster, e))

        def refresh_some_clusters_for_fetch(self,_clusters):
                '''Called once per pmFetch batch handling, before
                prometheus_fetch_callback calls.  Creates threads to
                fetch data in parallel.
                '''
                clusters = [int(l) for l in _clusters] # convert from PyLong
                threads = []
                for c in clusters:
                        t = threading.Thread(target=self.refresh_worker,
                                             args=(c,)) # <- important comma
                        threads.append(t)
                        t.daemon = True
                        t.start()
                for t in threads:
                        t.join() # XXX: timeout maybe?
                        
                # NB: this particular approach not only fetches the remote documents
                # in parallel, but also -processes- them in parallel, up to and including
                # calling the python pmda bindings from various threads.  This seems to
                # be OK.  The pmda main thread is the only one that will actually talk to
                # pmcd, based on the python shared dicts / callbacks, but that only happens
                # when all these threads are dead.  The various threads don't share any python-side data structures.
                        
        def set_need_refresh(self):
                cpmda.set_need_refresh()
                self.pmns_refresh()

        def debug(self,s):
                # XXX: conditionalize
                super(PrometheusPMDA,self).log("debug: "+s)
                # sys.stderr.write('debug:' + s + '\n')

        def log(self,s):
                super(PrometheusPMDA,self).log(s)
                # sys.stderr.write('log:' + s + '\n')
                        
                        
if __name__ == '__main__':
        parser = argparse.ArgumentParser(description='Prometheus PMDA.',
                                         formatter_class=argparse.ArgumentDefaultsHelpFormatter)
        parser.add_argument('-c','--config',
                            type=str,
                            default=os.getenv('PCP_PMDAS_DIR')+'/prometheus/urls.d',
                            help='set URL configuration directory')
        args = parser.parse_args()

        pmda = PrometheusPMDA('prometheus', 144, args.config)
        pmda.run()
