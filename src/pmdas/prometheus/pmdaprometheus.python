#!/usr/bin/env pmpython
'''
Performance Metrics Domain Agent exporting Prometheus endpoint metrics.
'''
#
# Copyright (c) 2017 Ronak Jain.
# Copyright (c) 2017 Red Hat, Inc.
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 2 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
# or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
# for more details.
#

import cpmapi as c_api
import cpmda
from pcp.pmapi import pmUnits, pmContext, pmErr
from pcp.pmda import PMDA, pmdaMetric, pmdaIndom, pmdaInstid

import argparse
from collections import OrderedDict
from ctypes import c_int
import copy
import errno
import math
import json
import os
import re
import sys
import time
import pickle
import requests
import threading


MAX_CLUSTER = 0xfff    # ~ max. number of prometheus sources
MAX_METRIC = 0x3ff     # ~ max. number of metrics per source
MAX_INDOM = 0x7fffffff # product of above

# These numbers are combined to create uniqe numbers for several
# purposes.  The first two types are used only for internal
# pmdaprometheus purposes, and are not visible as indoms to pmapi
# clients.
#
# indom# 0: maps source nicknames to 12-bit "cluster" numbers, cluster#0 is not used
# indom# 1..4095: for each source=cluster, map metric names to pmid numbers
# indom# 4096 + cluster#*1024 ...+1023:  actual pmns indom for each metric


class Metric(object):
	''' Metric information class '''
	def __init__(self,source,name,metricnum,instances,pcpline,helpline,typeline):
                self.source = source
                self.name = name
		self.pmid = source.pmda.pmid(source.cluster,metricnum)
                self.indom_number = (MAX_CLUSTER+1 +
                                     (source.cluster * (MAX_METRIC+1)) +
                                     metricnum)
                self.instances = PersistentNameTable(self.source.pmda,
                                                     self.indom_number,
                                                     MAX_INDOM)
                # XXXX PCP - real name; : unquoting; heuristics galore
                self.mtype = c_api.PM_TYPE_DOUBLE
                self.msem = c_api.PM_SEM_INSTANT   # XXX
                self.munits = pmUnits(0,0,0,0,0,0) # XXX
                if instances:
                        self.mindom = self.indom_number
                else:
                        self.mindom = c_api.PM_INDOM_NULL
                self.obj = pmdaMetric(self.pmid,self.mtype,self.mindom,self.msem,self.munits)
                self.mname = self.source.name + '.' + self.name.replace(":",".") # XXX
                self.description = helpline # XXX unescape
                self.source.pmda.add_metric(self.mname, self.obj, self.description)
                self.source.pmda.debug("created metric %x (%s)" % (self.pmid, self.mname))
                pass

        def clear_values(self):
                pass
        
        def store_inst(self,labels,value):
                pass
        
        def fetch_inst(self,inst): # fetch instance
                pass
                

class PersistentNameTable(object):
	'''Persistent name table.  Answers name-to-number queries by assigning
        persistent ids.  Updates pmda's indom table intermittently.
        Persistent by saving dictionary in $PCP_VAR_DIR/pmdas/,
        similarly to how pmdaCache functions do.
        '''
 
	def __init__(self,pmda,indom,maxnum):
		self.pmda = pmda
		self.indom = indom
                self.maxnum = maxnum
                self.need_save = False
                self.store_file_name = '%s/pmdas/%d.%d.py' % (os.environ['PCP_VAR_DIR'],
                                                              pmda.domain, indom)
                try: # slightly used!
                        with open(self.store_file_name,'r') as f:
                                self.instances = pickle.load(f)
                                self.pmda.debug("loaded %s" % self.store_file_name)
                                self.need_save = True # for pmda purposes at least
                except Exception as e: # new!
                        self.instances = [] # won't be saved till nonempty

                self.names_to_instances = {}
                for i,n in enumerate(self.instances):
                        self.names_to_instances[n] = i
                # prime the pmda indom table with an empty list
                self.pmdaindom = pmdaIndom(pmda.indom(self.indom), [])
		self.pmda.add_indom(self.pmdaindom)
                self.save() # replace it with real data now, if non-empty
                
        def save(self):
                '''Push values to the PMDA layer as well as to the backing store file.'''
                if self.need_save:
                        # save to the pmda C layer
                        indom_array = [] # pmdaInstid array, computed on demand
                        for i,n in enumerate(self.instances):
                                indom_array.append(pmdaInstid(c_int(i),n))
		        self.pmda.replace_indom(self.pmdaindom, indom_array)
                        # save to disk too
                        try: # slightly used!
                                with open(self.store_file_name,'w') as f:
                                        pickle.dump(self.instances, f)
                                        self.pmda.debug("saved %s" % self.store_file_name)
                                self.need_save = False # reset only on success
                        except Exception as e:
                                self.pmda.log("cannot save %s: %s" % (self.store_file_name, e))
                        

	def intern_lookup_value(self, name):
		'''Add/lookup given name, return its persistent identifier.'''
                if name in self.names_to_instances: # fast path
                        return self.names_to_instances[name]
                else: # new name
                        num = len(self.instances)
                        if (num > self.maxnum):
                                raise ValueError('Too many (%d) different names' % num)
                        self.instances.append(name)
                        self.names_to_instances[name] = num
                        assert self.instances[num] == name
                        self.need_save = True
                        return num

        
class SampleLineParser(object):
        '''A parser for one metric [{instance}] value [timestamp] line.  A
        state machine required since we're lexing text with embedded
        quoted freeform strings with punctuation, etc., so can't
        simply do substring searching.
        '''

        def parse_metric_name_start(self,char):
                if char.isspace():
                        pass
                else:
                        self.state = self.parse_metric_name
                        self.name = char

        def parse_metric_name(self,char):
                if char == '{':
                        self.state = self.parse_label_name_start
                        self.labels = {}
                elif char.isspace():
                        self.state = self.parse_post_metric_name
                else:
                        self.name += char

        def parse_post_metric_name(self,char):
                if char.isspace():
                        pass
                elif char == '{':
                        self.state = self.parse_label_name_start
                        self.labels = {}
                else:
                        self.state = self.parse_value
                        self.value = char

        def parse_label_name_start(self,char):
                if char.isspace():
                        pass
                elif char == '}':
                        self.state = self.parse_post_labels
                else:
                        self.state = self.parse_label_name
                        self.lname = char

        def parse_label_name(self,char):
                if char.isspace():
                        self.state = self.parse_label_equals
                elif char == '=':
                        self.state = self.parse_label_value_start
                else:
                        self.lname += char

        def parse_label_equals(self,char):
                if char.isspace():
                        pass
                elif char == '=':
                        self.state = self.parse_label_value_start
                else:
                        raise ValueError("Expected =")

        def parse_label_value_start(self,char):
                if char.isspace():
                        pass
                elif char == '"':
                        self.state = self.parse_label_value
                        self.lvalue = ""
                else:
                        raise ValueError("Expected \"")

        def parse_label_value(self,char):
                if char == '\\':
                        self.state = self.parse_label_value_escapechar
                elif char == '"':
                        self.state = self.post_label_value
                        self.labels[self.lname]=self.lvalue
                        self.lname = None
                        self.lvalue = None
                else:
                        self.lvalue += char
                                              
        def parse_label_value_escapechar(self,char):
                # XXX: maybe pass through \-escaped identifiers literally through to pcp
                # otherwise we'd have to filter them out at indom-instance-name creation
                if char == '\\':
                        self.state = self.parse_label_value
                        self.lvalue += '\\'
                elif char == 'n':
                        self.state = self.parse_label_value
                        self.lvalue += '\n'
                elif char == '"':
                        self.state = self.parse_label_value
                        self.lvalue += '\"'
                else:
                        self.state = self.parse_label_value
                        self.lvalue += '\\' + char # transcribe \XYZ literally
        
        def post_label_value(self,char):
                if char.isspace():
                        pass
                elif char == ',':
                        self.state = self.parse_label_name_start
                elif char == '}':
                        self.state = self.parse_post_labels
                else:
                        raise ValueError("Expected , or }")

        def parse_post_labels(self,char):
                if char.isspace():
                        pass
                else:
                        self.state = self.parse_value
                        self.value = char
                                              
        def parse_value(self,char):
                if char.isspace(): # timestamp possibly following
                        self.state = self.parse_chomp
                else:
                        self.value += char

        def parse_chomp(self,char): # ignored stuff
                pass

        def __init__(self,line):
                # mis-initialize output variables to force state
                # machine transitions to do it right
                self.name = None
                self.value = None
                self.labels = None
                self.lname = None
                self.lvalue = None

                # run state machine
                self.state = self.parse_metric_name_start
                for char in line:
                        self.state(char)

                assert self.name
                assert self.value

                                              
class Source(object):
	def __init__(self, name, cluster, path, pmda):
		self.name = name # source nickname
                self.cluster = cluster # unique/persistent id# for nickname
		self.path = path # pathname to .url file
		self.pmda = pmda # the shared pmda

                self.requests = requests.Session() # allow persistent connections etc.
                
                # persistently assign numeric id to our metrics
		self.pmids_table = PersistentNameTable(self.pmda, cluster, MAX_METRIC)
                
                self.metrics_by_name = {} # name -> Metric
                self.metrics_by_pmid = {} # pmid -> Metric
                

        def parse_metric_line(self,line,pcpline,helpline,typeline):
                '''
                Parse the sample line, identify/create corresponding metric & instance.
                '''
                try:
                        sp = SampleLineParser(line)
                        # self.pmda.debug("parsed '%s' -> %s %s %s" % (line, sp.name, sp.labels, sp.value))
                        if sp.name in self.metrics_by_name:
                                m = self.metrics_by_name[sp.name]
                                assert self.metrics_by_pmid[m.pmid] == m
                        else:
                                metricnum = self.pmids_table.intern_lookup_value(sp.name)
                                m = Metric(self,sp.name,metricnum,sp.labels,
                                           pcpline,helpline,typeline)
                                self.metrics_by_name[sp.name] = m
                                self.metrics_by_pmid[m.pmid] = m
                                self.pmda.set_need_refresh()

                        m.store_inst(sp.labels,sp.value)
                except Exception as e:
                        self.pmda.log("cannot parse %s: %s" % (line, e))
                pass


        def parse_lines(self,text):
                '''
                Refresh all the metric metadata as it is found, including creating
                new metrics; signal set_need_refresh() if changed
                Store away metric values for subsequent fetch()es.
                Parse errors may result in exceptions.  That's OK, we
                don't try heroics to parse non-compliant data.
                '''

                lines = text.splitlines()
                pcpline = None
                helpline = None
                typeline = None
                state="metadata"
                for line in lines:
                        # self.pmda.debug("line: %s state: %s" % (line, state))
                        l = line.strip() # whitespace
                        if l == "": # blank line, ignore, no state change
                                continue
                        elif l.startswith("#"): # comment
                                if state == "metrics":
                                        state = "metadata"
                                        pcpline = None # NB: throw away previous block's metadata
                                        helpline = None
                                        typeline = None

                                lp = l.split()
                                if len(lp) < 4:
                                        continue
                                # NB: for a well-formed exporter file,
                                # the # metadata blocks must precede
                                # the metric values; we can ignore
                                # lp[2].
                                if lp[1] == 'PCP': # XXX: extend, regularize, document
                                        pcpline = ' '.join(lp[3:])
                                elif lp[1] == 'HELP':
                                        helpline = ' '.join(lp[3:]) # XXX unescape \\ \n
                                elif lp[1] == 'TYPE':
                                        typeline = ' '.join(lp[3:])
                                else:
                                        pass # ignore other comment lines
                        else: # metric{...} value line
                                state = "metrics"
                                self.parse_metric_line(l,pcpline,helpline,typeline)
                

        def refresh(self):
                '''
                Find the target URL by reading .url file.
                Fetch the target URL.
                Parse the resulting document.
                '''
                # clear cached values from all my metrics
                for n,m in self.metrics_by_name.items():
                        m.clear_values()

                # XXX: ditch metrics no longer found in document
                                              
                # (re)read the URL from given file
                try:
                        url = open(self.path,'r').read().strip()
                except Exception as e:
                        self.pmda.log("cannot read %s: %s" % (self.path, e))
                        return
                # fetch the URL
                try:
                        r = self.requests.get(url,timeout=1) # XXX parametrize
                        self.parse_lines(r.text)
                        self.pmids_table.save()
                        self.pmda.debug("fetched %d bytes from %s" % (len(r.text), url))
                except Exception as e:
                        self.pmda.log("cannot fetch %s: %s" % (url, e))
                        return
                
        def fetch(self, item, inst):
                try:
                        m = self.metrics_by_pmid[item]
                        return m.fetch_inst(inst)
                except:
		        return [c_api.PM_ERR_PMID, 0]


class PrometheusPMDA(PMDA):
	def __init__(self,pmda_name,domain,config):
		''' Initialize the PMDA'''
                # urgent: say hi the invoking pmcd, redirect stderr etc.
		PMDA.__init__(self,pmda_name,domain)
		self.connect_pmcd()
                # now everything else may take time
		self.pmda_name = pmda_name
                self.config_dir = config
		self.debug_flag = ('PCP_PYTHON_DEBUG' in os.environ)

                # the list of configured sources
		self.source_by_name = {}
                # persistently assign numeric id to source names -> pmid "cluster" numbers
		self.cluster_table = PersistentNameTable(self, 0, MAX_CLUSTER)
                reserved_cluster = self.cluster_table.intern_lookup_value("*reserved-source2cluster*")
                assert reserved_cluster == 0
		self.source_by_cluster = {}

                self.log("starting up!")
                # pmns ops
		self.set_refresh_metrics(self.refresh_metrics)
                # metric fetch
		self.set_refresh_all(self.refresh_all)
		self.set_fetch_callback(self.fetch_callback)


        def refresh_metrics(self):
                # maybe not needed
                pass

        def assert_source_invariants(self, name=None, cluster=None):
                '''
                Assert some invariants about the known sources
                '''
                if name:
                        s = self.source_by_name[name]
                        assert s == self.source_by_cluster[s.cluster]
                if cluster:
                        s = self.source_by_cluster[cluster]
                        assert s == self.source_by_name[s.name]

	def rescan_confdir(self):
                '''
                Scan the configuration directory for any new .url files containing
                prometheus URLs.  Ensure there is a Source registered in
                the self.source_by_name dictionary for each one.
                '''
                nickname_regexp = re.compile(r"^[A-Za-z]\w+$")
                
                # XXX: skip if self.configdir hasn't changed
                # XXX: nuke sources related to removed files
                self.log("walking %s" % self.config_dir)
                save_cluster_table = False
		for root, dirs, files in os.walk(self.config_dir):
			for file in files:
                                # compute nickname for source:
                                # the part of the filename before .url
                                file_split = os.path.splitext(file)
                                self.debug("found %s/%s => %s" % (root, file, file_split))
                                if len(file_split) != 2 or file_split[1] != ".url":
                                        continue
                                name = file_split[0]
                                if not nickname_regexp.match(name):
					self.log("Bad nickname %s" % file)
                                        continue

                                if name in self.source_by_name:
                                        self.assert_source_invariants(name=name)
                                        pass
                                else:
                                        try:
				                path = os.path.join(root, file)
					        cluster = self.cluster_table.intern_lookup_value(name)
				                source = Source(name, cluster, path, self)
                                                self.source_by_name[source.name] = source
                                                self.source_by_cluster[source.cluster] = source
                                                save_cluster_table = True
                                                self.set_need_refresh() # update pmda/pmns
                                                self.log("Found source %s cluster %d" % (name, cluster))
                                        except Exception as e:
                                                self.log("Error allocating new cluster/source %s (%s)" % (name, e))
                if save_cluster_table:
                        self.cluster_table.save()
                                      
	def fetch_callback(self, cluster, item, inst):
		''' Main fetch callback which returns the value of the metric '''
                self.assert_source_invariants(cluster=cluster)
                try:
		        if cluster in self.source_by_cluster:
			        return self.source_by_cluster[cluster].fetch(item, inst)
                        else:
		                return [c_api.PM_ERR_PMID, 0]
                except Exception as e:
		        return [c_api.PM_ERR_PMID, 0]

        def refresh_worker(self,cluster):
                try:
                        self.assert_source_invariants(cluster=cluster)
                        self.source_by_cluster[cluster].refresh()
                except Exception as e:
                        self.log("Cannot refresh cluster %d: %s" % (cluster, e))
        
	def refresh_all(self,clusters):
		'''
                Called once, before prometheus_fetch_callback calls.
                Creates threads to fetch data in parallel.
		'''
		threads = []
		for i in range(len(clusters)):
			t = threading.Thread(target=self.refresh_worker,
					     args=(clusters[i],)) # <- important comma
			threads.append(t)
			t.daemon = True
			t.start()

		# Wait for all the threads to terminate
		for t in threads:
			t.join()


        def set_need_refresh(self):
                cpmda.set_need_refresh()

        def debug(self,s):
                sys.stderr.write('debug:' + s + '\n')

        def log(self,s):
                sys.stderr.write('log:' + s + '\n')
                        
                        
if __name__ == '__main__':
	parser = argparse.ArgumentParser(description='Prometheus PMDA.',
                                         formatter_class=argparse.ArgumentDefaultsHelpFormatter)
        parser.add_argument('-c','--config',
                            type=str,
                            default=os.getenv('PCP_PMDAS_DIR')+'/prometheus/urls.d',
                            help='set URL configuration directory')
	args = parser.parse_args()

	pmda = PrometheusPMDA('prometheus', 144, args.config)
        pmda.rescan_confdir()
        pmda.refresh_all([1, 2, 3, 4, 5, 6, 7, 8])
        pmda.run()
